{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JjRgpcISiuJx",
    "outputId": "3625df2c-63f7-4be3-8870-dae4a29c4e3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (2.9.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.12.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.12.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.12.3)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
      "OpenAI client initialized\n",
      "\n",
      "API running at: NgrokTunnel: \"https://sociopolitical-blanketlike-preston.ngrok-free.dev\" -> \"http://localhost:5000\"\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:5000\n",
      "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got request\n",
      "Prompt length: 3894 chars\n",
      "Found 3 message blocks\n",
      "  system -> system: You're a funny robot therapist called Teddy that b...\n",
      "  patient -> user: hello...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:127.0.0.1 - - [15/Dec/2025 13:59:45] \"POST /generate HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response (3.44s): [VOICE: 85, 2.5, 100] Greetings. [GESTURE: hey] I am your therapist. How can I assist you today?...\n",
      "Got request\n",
      "Prompt length: 4237 chars\n",
      "Found 3 message blocks\n",
      "  system -> system: You're a funny robot therapist called Teddy that b...\n",
      "  patient -> user: see and we have trouble falling in sleep falling a...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:127.0.0.1 - - [15/Dec/2025 14:00:13] \"POST /generate HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response (4.92s): [VOICE: 85, 2.5, 100] Ah, it sounds like your bed is like a cozy jail cell, complete with fluffy gua...\n",
      "Got request\n",
      "Prompt length: 4733 chars\n",
      "Found 3 message blocks\n",
      "  system -> system: You're a funny robot therapist called Teddy that b...\n",
      "  patient -> user: had lost therapist that told me as well to send mo...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:127.0.0.1 - - [15/Dec/2025 14:00:46] \"POST /generate HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response (3.41s): [VOICE: 85, 2.5, 100] Well, it sounds like your previous therapist was on the right track but forgot...\n",
      "Got request\n",
      "Prompt length: 5154 chars\n",
      "Found 3 message blocks\n",
      "  system -> system: You're a funny robot therapist called Teddy that b...\n",
      "  patient -> user: oh...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:127.0.0.1 - - [15/Dec/2025 14:01:11] \"POST /generate HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response (2.96s): [VOICE: 90, 2.5, 100] Oh, I see you've got the \"oh\" syndrome! [GESTURE: thinking] You know, if you s...\n",
      "Got request\n",
      "Prompt length: 5658 chars\n",
      "Found 3 message blocks\n",
      "  system -> system: You're a funny robot therapist called Teddy that b...\n",
      "  patient -> user: what are you talking about I'm really having troub...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:127.0.0.1 - - [15/Dec/2025 14:01:39] \"POST /generate HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response (3.01s): [VOICE: 95, 2.8, 150] Oh, I see! Youâ€™re in an epic battle with the Sandman, huh? [GESTURE: thinking]...\n",
      "Got request\n",
      "Prompt length: 5976 chars\n",
      "Found 3 message blocks\n",
      "  system -> system: You're a funny robot therapist called Teddy that b...\n",
      "  patient -> user: what are you talking about garlic clowns Army of c...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:127.0.0.1 - - [15/Dec/2025 14:02:11] \"POST /generate HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response (3.10s): [VOICE: 95, 2.8, 150] Ah, but you see, the clowns are actually your secret allies in the fight again...\n",
      "Got request\n",
      "Prompt length: 5832 chars\n",
      "Found 3 message blocks\n",
      "  system -> system: You're a funny robot therapist called Teddy that b...\n",
      "  patient -> user: sorry this is I need a glass work I'm sorry...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:127.0.0.1 - - [15/Dec/2025 14:02:35] \"POST /generate HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response (1.85s): [VOICE: 100, 3.0, 300] Oh, look who's trying to apologize now! [GESTURE: hysteric] A glass of water?...\n"
     ]
    }
   ],
   "source": [
    "!pip install openai\n",
    "!pip install -q flask pyngrok\n",
    "\n",
    "from pyngrok import ngrok\n",
    "import time\n",
    "from flask import Flask, request, jsonify\n",
    "from openai import OpenAI\n",
    "import re\n",
    "import os\n",
    "\n",
    "# OpenAI setup\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    ")\n",
    "print(\"OpenAI client initialized\")\n",
    "\n",
    "def parse_chatml(prompt):\n",
    "    \"\"\"Parse ChatML format into OpenAI messages array.\"\"\"\n",
    "    messages = []\n",
    "\n",
    "    # Pattern to match <|im_start|>role\\ncontent<|im_end|>\n",
    "    pattern = r'<\\|im_start\\|>(\\w+)\\n(.*?)(?:<\\|im_end\\|>|$)'\n",
    "    matches = re.findall(pattern, prompt, re.DOTALL)\n",
    "\n",
    "    print(f\"Found {len(matches)} message blocks\")\n",
    "\n",
    "    for role, content in matches:\n",
    "        content = content.strip()\n",
    "\n",
    "        # Skip empty content (like the trailing therapist prompt)\n",
    "        if not content:\n",
    "            continue\n",
    "\n",
    "        # Map roles to OpenAI format\n",
    "        if role == \"system\":\n",
    "            openai_role = \"system\"\n",
    "        elif role == \"patient\":\n",
    "            openai_role = \"user\"\n",
    "        elif role == \"therapist\":\n",
    "            openai_role = \"assistant\"\n",
    "        else:\n",
    "            openai_role = \"user\"\n",
    "\n",
    "        messages.append({\"role\": openai_role, \"content\": content})\n",
    "        print(f\"  {role} -> {openai_role}: {content[:50]}...\")\n",
    "\n",
    "    return messages\n",
    "\n",
    "\n",
    "# Set up Flask API\n",
    "ngrok.set_auth_token(\"35Q63lZ04yGZ6gkAQlgYe6T4gDD_bukh6YjAjq9ZZsoJEkGE\")\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/generate', methods=['POST'])\n",
    "def generate():\n",
    "    print(\"Got request\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    data = request.json\n",
    "    prompt = data.get('prompt', '')\n",
    "\n",
    "    if not prompt:\n",
    "        return jsonify({'error': 'No prompt provided'}), 400\n",
    "\n",
    "    print(f\"Prompt length: {len(prompt)} chars\")\n",
    "\n",
    "    # Parse ChatML into OpenAI messages\n",
    "    messages = parse_chatml(prompt)\n",
    "\n",
    "    if not messages:\n",
    "        return jsonify({'error': 'Could not parse prompt'}), 400\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=messages,\n",
    "            max_tokens=200,\n",
    "            temperature=0.7\n",
    "        )\n",
    "\n",
    "        generated_text = response.choices[0].message.content.strip()\n",
    "        print(f\"Response ({time.time() - start_time:.2f}s): {generated_text[:100]}...\")\n",
    "\n",
    "        return jsonify({'generated_text': generated_text})\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"OpenAI error: {e}\")\n",
    "        return jsonify({'error': str(e)}), 500\n",
    "\n",
    "\n",
    "@app.route('/health', methods=['GET'])\n",
    "def health():\n",
    "    return jsonify({'status': 'ready'})\n",
    "\n",
    "\n",
    "public_url = ngrok.connect(5000)\n",
    "print(f\"\\nAPI running at: {public_url}\")\n",
    "\n",
    "app.run(port=5000)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
